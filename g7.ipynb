{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXIGAIhxu4lr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import image as IMG\n",
        "import imageio\n",
        "import PIL\n",
        "from PIL import Image, ImageEnhance\n",
        "import torchvision as tv\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from skimage.transform import rescale, resize, downscale_local_mean\n",
        "from pathlib import Path\n",
        "import torchvision.transforms #import (Compose, ColorJitter, RandomGrayscale, RandomHorizontalFlip, RandomOrder, RandomRotation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GkZelTPu4lw"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():     # Make sure GPU is available\n",
        "    dev = torch.device(\"cuda:0\")\n",
        "    kwar = {'num_workers': 8, 'pin_memory': True}\n",
        "    cpu = torch.device(\"cpu\")\n",
        "else:\n",
        "    print(\"Warning: CUDA not found, CPU only.\")\n",
        "    dev = torch.device(\"cpu\")\n",
        "    kwar = {}\n",
        "    cpu = torch.device(\"cpu\")\n",
        "\n",
        "np.random.seed(551)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1KP47VWu4lw"
      },
      "outputs": [],
      "source": [
        "images_path = 'chexpertData_new/'\n",
        "images_path_new = 'GB7_new/'\n",
        "labels_path = 'train_new.csv'\n",
        "test_path = 'test_2.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Puf5w5zwu4lx"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(labels_path)\n",
        "#train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLaEYqNKu4ly"
      },
      "outputs": [],
      "source": [
        "frontal = list(map(str, train_df[train_df['label']=='frontal']['target_name'])) \n",
        "lateral = list(map(str, train_df[train_df['label']=='lateral']['target_name']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXDzZh07u4ly"
      },
      "outputs": [],
      "source": [
        "images = np.concatenate([frontal, lateral])\n",
        "image_names = []\n",
        "image_labels = {}\n",
        "\n",
        "for image in images:\n",
        "    image_name = images_path + '/' + image\n",
        "    if image in frontal:\n",
        "        image_labels.update({image_name: 1})\n",
        "    else:\n",
        "        image_labels.update({image_name: 0})\n",
        "    image_names.append(image_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tKLOEEru4lz"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "import cv2\n",
        "resized_images = {}\n",
        "for image_name in tqdm(image_names):\n",
        "  image = cv2.imread(image_name, 0)\n",
        "  resized_image = cv2.resize(image, (64, 64))\n",
        "  resized_images[image_name] = resized_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hlo4AcWHu4l0"
      },
      "outputs": [],
      "source": [
        "for i, k in enumerate(resized_images):\n",
        "    if i == 0:\n",
        "        print(resized_images[k].shape)\n",
        "        plt.imshow(resized_images[k], cmap='gray')\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "voIx4hrru4l1"
      },
      "outputs": [],
      "source": [
        "class LungsClassificationDataset(Dataset):\n",
        "    def __init__(self, image_names, resized_images, image_labels, transformations=None):\n",
        "        self.image_names = image_names\n",
        "        self.resized_images = resized_images\n",
        "        self.image_labels = image_labels\n",
        "        self.transformations = transformations\n",
        "                                            \n",
        "    def __len__(self):\n",
        "        return len(self.image_names)\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        image_path = self.image_names[index]\n",
        "\n",
        "        #image_0 = self.resized_images[image_path]\n",
        "        image = Image.open(image_path)\n",
        "        label = self.image_labels[image_path]\n",
        "\n",
        "        if self.transformations:\n",
        "            image = self.transformations(image)\n",
        "        \n",
        "        image = (np.asarray(image.convert(\"L\")) / 256) ** 0.4\n",
        "\n",
        "        image = torch.tensor(image)\n",
        "        label = torch.tensor(label)\n",
        "\n",
        "        result = {\"image\":image,\"label\":label}\n",
        "        return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhLKaW7Ou4l2"
      },
      "outputs": [],
      "source": [
        "train_image_names, val_image_names = train_test_split(image_names, test_size=0.2)\n",
        "transform = torchvision.transforms.Compose([torchvision.transforms.ColorJitter(), torchvision.transforms.RandomHorizontalFlip(p=0.5)])\n",
        "\n",
        "train = LungsClassificationDataset(train_image_names, resized_images, image_labels, transformations=transform)\n",
        "validation = LungsClassificationDataset(val_image_names, resized_images, image_labels, transformations=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YE1_Xf6ku4l2"
      },
      "outputs": [],
      "source": [
        "imageWidth, imageHeight = train[0]['image'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6AOXicpu4l3"
      },
      "outputs": [],
      "source": [
        "for i in tqdm(range((len(train)))):\n",
        "    sample = train[i]\n",
        "    plt.imshow(sample['image'], cmap='gray')\n",
        "    plt.show()\n",
        "    print(sample['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ivczhxiu4l6"
      },
      "outputs": [],
      "source": [
        "sample = train[22]\n",
        "plt.imshow(sample['image'], cmap='gray')\n",
        "print(sample['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qqcovs_Wu4l6"
      },
      "outputs": [],
      "source": [
        "len(validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lW74si_u4l7"
      },
      "outputs": [],
      "source": [
        "class LungModel(nn.Module):\n",
        "    def __init__(self,width,height): \n",
        "        super(LungModel,self).__init__()  \n",
        "\n",
        "        numConvs1 = 8\n",
        "        numConvs2 = 16\n",
        "        numConvs3 = 32\n",
        "        numConvs4 = 64\n",
        "        convSize = 3\n",
        "       \n",
        "        self.cnv1 = nn.Conv2d(in_channels=1, out_channels=numConvs1, kernel_size=convSize)\n",
        "        self.cnv2 = nn.Conv2d(in_channels=numConvs1, out_channels=numConvs2, kernel_size=convSize)\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
        "        self.cnv3 = nn.Conv2d(in_channels=numConvs2, out_channels=numConvs3, kernel_size=convSize)\n",
        "        self.cnv4 = nn.Conv2d(in_channels=numConvs3, out_channels=numConvs4, kernel_size=convSize)\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
        "        \n",
        "        denseSize1 = 512\n",
        "        denseSize2 = 100\n",
        "      \n",
        "        self.dense1 = nn.Linear(64*13*13, denseSize1)\n",
        "        self.dense2 = nn.Linear(denseSize1, denseSize2)\n",
        "        self.dense3 = nn.Linear(denseSize2, 1)\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        \n",
        "    def forward(self,x):\n",
        "\n",
        "        x = F.elu(self.cnv1(x))\n",
        "        x = F.elu(self.cnv2(x))\n",
        "        x = self.maxpool1(x)\n",
        "        x = F.elu(self.cnv3(x))\n",
        "        x = F.elu(self.cnv4(x))\n",
        "        x = self.maxpool2(x)\n",
        "        x = x.view(-1,self.num_flat_features(x))\n",
        "        x = F.elu(self.dense1(x)) \n",
        "        x = self.dropout(x)\n",
        "        x = F.elu(self.dense2(x)) \n",
        "        x = self.dropout(x)\n",
        "        x = self.dense3(x)        \n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykGUegYGu4l7"
      },
      "outputs": [],
      "source": [
        "model = LungModel(imageWidth, imageHeight).to(dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Zyll_T1u4l7"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train, batch_size=50, shuffle=True, drop_last=True)\n",
        "val_loader = DataLoader(validation, batch_size=50, shuffle=True, drop_last=True)\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=3e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQEQ39D2u4l8"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "print(time.time())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARNZ6RADu4l8"
      },
      "outputs": [],
      "source": [
        "num_epochs = 20\n",
        "\n",
        "t = time.time() \n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    time_start = time.time()\n",
        "\n",
        "    for sample_idx, sample in enumerate(train_loader):\n",
        "        image, label = sample['image'].unsqueeze(1).float(), sample['label'].unsqueeze(1).float()\n",
        "        image, label = image.to(dev), label.to(dev)\n",
        "\n",
        "        prediction = model(image)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(prediction, label)\n",
        "        loss.backward()\n",
        "        optimizer.step() \n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        if sample_idx % 100 == 0:\n",
        "            print(loss.item())\n",
        "\n",
        "    val_loss = 0\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for sample in val_loader:\n",
        "            image, label = sample['image'].unsqueeze(1).float(), sample['label'].unsqueeze(1).float()\n",
        "            image, label = image.to(dev), label.to(dev)\n",
        "            prediction = model(image)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(prediction, label)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "    val_loss /= len(val_loader)\n",
        "\n",
        "    print(f\"Epoch: {epoch}; Time Epoch: {time.time() - time_start}\\nTraining Loss: {train_loss}\\nValidation Loss: {val_loss}\\n-----\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JHR3Ieou4l8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMKAtGqiu4l9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}